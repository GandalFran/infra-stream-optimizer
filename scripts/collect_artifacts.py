import os
import subprocess
import time
import json
import requests
import datetime
import numpy as np
import re
from pathlib import Path

# Config
ARTIFACTS_DIR = Path("artifacts")
PROMETHEUS_URL = "http://localhost:9090"

# Get namespace from environment (set by run_k8s_experiment.py)
K8S_NAMESPACE = os.getenv("K8S_NAMESPACE", "default")

def normalize_log_timestamps(log_content, reference_timestamp=None):
    """Normalize log timestamps to T+Xs format (relative from first timestamp)."""
    iso_pattern = re.compile(r'(\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}[.,]\d{3,9})')
    
    first_timestamp_found = reference_timestamp
    lines = log_content.split('\n')
    normalized_lines = []
    
    for line in lines:
        match = iso_pattern.search(line)
        if match:
            timestamp_str = match.group(1)
            ts_normalized = timestamp_str.replace(',', '.').replace(' ', 'T')
            try:
                if 'Z' in ts_normalized or '+' in ts_normalized or ts_normalized.count('-') > 2:
                    current_ts = datetime.datetime.fromisoformat(ts_normalized.replace('Z', '+00:00'))
                else:
                    current_ts = datetime.datetime.fromisoformat(ts_normalized)
                
                if not first_timestamp_found:
                    first_timestamp_found = current_ts
                
                delta = (current_ts - first_timestamp_found).total_seconds()
                relative_time = f"T+{delta:.3f}s"
                normalized_line = iso_pattern.sub(relative_time, line, count=1)
                normalized_lines.append(normalized_line)
            except ValueError:
                normalized_lines.append(line)
        else:
            normalized_lines.append(line)
    
    return {"content": '\n'.join(normalized_lines), "first_ts": first_timestamp_found}

def run(cmd):
    subprocess.run(cmd, shell=True, check=True)

def query_prometheus(query, start_time, end_time, step="1s"):
    try:
        print(f"DEBUG: Querying {query}...")
        response = requests.get(
            f"{PROMETHEUS_URL}/api/v1/query_range",
            params={
                "query": query,
                "start": start_time,
                "end": end_time,
                "step": step
            },
            timeout=5 # Short timeout to fail fast
        )
        if response.status_code == 200:
            data = response.json().get('data', {})
            return data.get('result', [])
        else:
            print(f"Error querying {query}: {response.text}")
            return []
    except Exception as e:
        print(f"Failed to connect to Prometheus for {query}: {e}")
        return []

def calculate_stats(series_values):
    # series_values is list of [ts, val]
    if not series_values:
        return {"mean": 0, "p50": 0, "p95": 0, "p99": 0, "max": 0}
    
    vals = [float(v[1]) for v in series_values]
    if not vals:
        return {"mean": 0, "p50": 0, "p95": 0, "p99": 0, "max": 0}

    return {
        "mean": float(np.mean(vals)),
        "p50": float(np.percentile(vals, 50)),
        "p95": float(np.percentile(vals, 95)),
        "p99": float(np.percentile(vals, 99)),
        "max": float(np.max(vals))
    }

def collect_artifacts(run_id="run_latest", scenario_id="unknown", k8s_mode=False):
    run_dir = ARTIFACTS_DIR / run_id
    run_dir.mkdir(parents=True, exist_ok=True)
    
    # Create logs subdirectory
    logs_dir = run_dir / "logs"
    logs_dir.mkdir(exist_ok=True)
    
    print(f"Collecting artifacts for {scenario_id} to {run_dir}...")
    
    # 0. Load Run Meta (Generated by run_experiment.py)
    run_meta_path = run_dir / "run_meta.json"
    run_meta = {}
    if run_meta_path.exists():
        try:
            with open(run_meta_path, "r") as f:
                run_meta = json.load(f)
            print("Loaded run_meta.json")
        except Exception as e:
            print(f"Failed to load run_meta.json: {e}")
            run_meta = {"error": f"Failed load: {e}"}
    else:
        print("Warning: run_meta.json not found! Using default.")
        run_meta = {
            "run_id": run_id,
            "scenario_id": scenario_id,
            "timestamp_utc": datetime.datetime.utcnow().isoformat(),
            "note": "Generated by collector (meta missing)"
        }

    # 1. Logs (Save individual service logs in logs/ subdirectory with normalized timestamps)
    services = ["workload-generator", "jobmanager", "taskmanager", "tuner", "constraint-gate", "kafka", "kafka-exporter"]
    
    # Capture first timestamp to normalize
    first_timestamp = None
    
    for svc in services:
        print(f"Saving logs for {svc}...")
        svc_log_path = logs_dir / f"{svc}.log"
        
        with open(svc_log_path, "w") as f:
            if k8s_mode:
                # K8s Mode: kubectl logs (with namespace)
                label = f"app={svc}"
                if svc in ["jobmanager", "taskmanager"]:
                    label = f"component={svc}"
                
                # Get pod names
                try:
                    pod_names_raw = subprocess.check_output(f"kubectl get pods -n {K8S_NAMESPACE} -l {label} -o jsonpath=\"{{.items[*].metadata.name}}\"", shell=True).decode('utf-8').strip()
                    if pod_names_raw:
                        pod_names = [p.strip("'").strip('"') for p in pod_names_raw.split()]
                        for pod_name in pod_names:
                            print(f"  Retrieving logs for pod {pod_name}...")
                            f.write(f"\n--- POD: {pod_name} ---\n")
                            res = subprocess.run(f"kubectl logs {pod_name} -n {K8S_NAMESPACE}", shell=True, capture_output=True, text=True)
                            if res.returncode == 0:
                                # Normalize timestamps
                                normalized_log = normalize_log_timestamps(res.stdout, first_timestamp)
                                if not first_timestamp and normalized_log["first_ts"]:
                                    first_timestamp = normalized_log["first_ts"]
                                f.write(normalized_log["content"])
                            else:
                                f.write(f"Failed to get logs: {res.stderr}\n")
                    else:
                         f.write(f"No pod found for {svc}")
                except Exception as e:
                    # Tuner is optional in baseline mode, suppress error
                    if svc == "tuner":
                         f.write(f"Tuner pod not found (expected in baseline mode).\n")
                    else:
                         f.write(f"Error getting logs for {svc}: {e}\n")

            else:
                # Docker Compose Mode
                subprocess.run(f"docker-compose logs --no-color {svc}", shell=True, stdout=f)

    # 2. Metrics
    end_time_ts = time.time()
    start_time_ts = end_time_ts - 900 # 15 mins
    
    queries = {
        "throughput_in": "sum(flink_taskmanager_job_task_operator_numRecordsInPerSecond)",
        "throughput_out": "sum(flink_taskmanager_job_task_operator_numRecordsOutPerSecond)",
        "backpressure": "avg(flink_taskmanager_job_task_isBackPressured)",
        "cpu_usage": "sum(flink_taskmanager_Status_JVM_CPU_Load)",
        "kafka_consumer_lag": "sum(kafka_consumergroup_lag{consumergroup='flink-consumer'})",
        "e2e_latency": "avg(flink_taskmanager_job_latency_source_id_operator_id_operator_subtask_index_latency{quantile='0.95'})"
    }
    
    metrics_timeseries = []
    summary_stats = {
        "e2e_latency_ms": {"p50": 0, "p95": 0, "p99": 0, "mean": 0},
        "throughput_in_eps": {"mean": 0, "p95": 0},
        "throughput_out_eps": {"mean": 0, "p95": 0},
        "backpressure_ratio": {"mean": 0, "p95": 0},
        "consumer_lag_records": {"max": 0, "p95": 0},
        "cpu_usage_cores": {"p95_total": 0}
    }

    print("Querying Prometheus...")
    for name, query in queries.items():
        results = query_prometheus(query, start_time_ts, end_time_ts)
        # Verify if results is list
        if not isinstance(results, list):
            print(f"Warning: Unexpected result format for {name}: {results}")
            results = []

        count = len(results)
        print(f"  -> {name}: found {count} series.")
        if count == 0:
            print(f"     [WARNING] No data found for {name}. Query: {query}")

        for res in results:
            values = res.get('values', [])
            
            metrics_timeseries.append({
                "name": name,
                "labels": res.get('metric', {}),
                "values": values
            })
            
            stats = calculate_stats(values)
            
            # Update summary stats based on metric name
            if name == "throughput_in":
                summary_stats["throughput_in_eps"] = {"mean": stats["mean"], "p95": stats["p95"]}
            elif name == "throughput_out":
                summary_stats["throughput_out_eps"] = {"mean": stats["mean"], "p95": stats["p95"]}
            elif name == "backpressure":
                summary_stats["backpressure_ratio"] = {"mean": stats["mean"], "p95": stats["p95"]}
            elif name == "kafka_consumer_lag":
                summary_stats["consumer_lag_records"] = {"max": stats["max"], "p95": stats["p95"]}
            elif name == "cpu_usage":
                 summary_stats["cpu_usage_cores"]["p95_total"] = stats["p95"]
            elif name == "e2e_latency":
                summary_stats["e2e_latency_ms"] = {
                    "p50": stats["p50"],
                    "p95": stats["p95"],
                    "p99": stats["p99"],
                    "mean": stats["mean"]
                }
    
    print("DEBUG: Summary Stats Preview:")
    print(json.dumps(summary_stats, indent=2))

    # Calculate time_range metadata for metrics_timeseries
    all_timestamps = []
    for metric in metrics_timeseries:
        for value_pair in metric.get("values", []):
            all_timestamps.append(float(value_pair[0]))
    
    time_range = {}
    if all_timestamps:
        all_timestamps.sort()
        time_range = {
            "start_time": all_timestamps[0],
            "end_time": all_timestamps[-1],
            "duration_sec": round(all_timestamps[-1] - all_timestamps[0], 2),
            "sample_count": len(all_timestamps),
            "sample_interval_sec": round((all_timestamps[-1] - all_timestamps[0]) / max(1, len(all_timestamps) - 1), 3) if len(all_timestamps) > 1 else 0
        }
    
    # Create final metrics timeseries with metadata
    metrics_timeseries_output = {
        "time_range": time_range,
        "metrics": metrics_timeseries
    }

    with open(run_dir / "metrics_timeseries.json", "w") as f:
        json.dump(metrics_timeseries_output, f, indent=2)

    # 3. Decisions (collect from tuner pod in K8s mode with namespace)
    print("Collecting decisions.jsonl from tuner...")
    import shutil
    if k8s_mode:
        try:
            # Check if tuner pod exists first
            tuner_pod_cmd = f"kubectl get pods -n {K8S_NAMESPACE} -l app=tuner -o jsonpath='{{.items[0].metadata.name}}'"
            tuner_pod_res = subprocess.run(tuner_pod_cmd, shell=True, capture_output=True, text=True)
            
            if tuner_pod_res.returncode == 0 and tuner_pod_res.stdout.strip():
                 tuner_pod = tuner_pod_res.stdout.strip().strip("'")
                 # Windows Fix: kubectl cp fails with absolute paths containing drive letters (C:) 
                 # because ':' is used as separator. We run command from the destination dir.
                 cmd = f"kubectl cp {K8S_NAMESPACE}/{tuner_pod}:/app/artifacts/decisions.jsonl decisions.jsonl"
                 subprocess.run(cmd, shell=True, cwd=str(run_dir), stderr=subprocess.DEVNULL)
                 print(f"  Copied decisions.jsonl from {tuner_pod}")
            else:
                 print("  Tuner pod not found, skipping decisions.jsonl (expected in baseline mode).")
        except Exception as e:
            print(f"  Skipping decisions.jsonl collection: {e}")
    else:
        # Docker Compose mode - copy from artifacts root
        global_artifacts = Path("artifacts")
        if (global_artifacts / "decisions.jsonl").exists():
            try:
                shutil.copy2(global_artifacts / "decisions.jsonl", run_dir / "decisions.jsonl")
            except Exception as e:
                print(f"Failed to copy decisions.jsonl: {e}")

    # 4. Result JSON (renamed to metrics.json)
    result_json = {
        "run_meta": run_meta,
        "slo": {
             "target_p95_e2e_ms": 3000
        },
        "summary": summary_stats,
        "artifacts": {
            "metrics_timeseries": "metrics_timeseries.json",
            "decisions_log": "decisions.jsonl" if (run_dir/"decisions.jsonl").exists() else None,
            "logs_dir": "logs/"
        }
    }

    with open(run_dir / "metrics.json", "w") as f:
        json.dump(result_json, f, indent=2)
        
    print(f"Artifact collection complete. Structure: logs/, metrics.json, metrics_timeseries.json")

if __name__ == "__main__":
    import sys
    # Usage: python collect_artifacts.py <run_id> <scenario_id> [--k8s]
    rid = sys.argv[1] if len(sys.argv) > 1 else "run_latest"
    sid = sys.argv[2] if len(sys.argv) > 2 else "unknown"
    k8s = "--k8s" in sys.argv
    collect_artifacts(rid, sid, k8s_mode=k8s)
